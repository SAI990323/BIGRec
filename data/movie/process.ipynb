{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ratings.dat', 'r')\n",
    "data = f.readlines()\n",
    "f = open('movies.dat', 'r', encoding='ISO-8859-1')\n",
    "movies = f.readlines()\n",
    "movie_names = [_.split('::')[1] for _ in movies]\n",
    "movie_ids = [_.split('::')[0] for _ in movies]\n",
    "movie_dict = dict(zip(movie_ids, movie_names))\n",
    "id_mapping = dict(zip(movie_ids, range(len(movie_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_dicts = dict()\n",
    "for line in data:\n",
    "    user_id, movie_id, rating, timestamp = line.split('::')\n",
    "    if user_id not in interaction_dicts:\n",
    "        interaction_dicts[user_id] = {\n",
    "            'movie_id': [],\n",
    "            'rating': [],\n",
    "            'timestamp': [],\n",
    "            'movie_title': [],\n",
    "        }\n",
    "    interaction_dicts[user_id]['movie_id'].append(movie_id)\n",
    "    interaction_dicts[user_id]['rating'].append(int(float(rating) > 3.0))\n",
    "    interaction_dicts[user_id]['timestamp'].append(timestamp)\n",
    "    interaction_dicts[user_id]['movie_title'].append(movie_dict[movie_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all.csv', 'w') as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'item_id', 'rating', 'timestamp', 'item_title'])\n",
    "    for user_id, user_dict in interaction_dicts.items():\n",
    "        writer.writerow([user_id, user_dict['movie_id'], user_dict['rating'], user_dict['timestamp'], user_dict['movie_title']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_interaction_list = []\n",
    "seq_len = 10\n",
    "for user_id in interaction_dicts:\n",
    "    temp = zip(interaction_dicts[user_id]['movie_id'], interaction_dicts[user_id]['rating'], interaction_dicts[user_id]['timestamp'])\n",
    "    temp = sorted(temp, key=lambda x: x[2])\n",
    "    result = zip(*temp)\n",
    "    interaction_dicts[user_id]['movie_id'], interaction_dicts[user_id]['rating'], interaction_dicts[user_id]['timestamp'] = [list(_) for _ in result]\n",
    "    for i in range(10, len(interaction_dicts[user_id]['movie_id'])):\n",
    "        if interaction_dicts[user_id]['rating'][i] == 0:\n",
    "            continue\n",
    "        sequential_interaction_list.append(\n",
    "            [user_id, interaction_dicts[user_id]['movie_id'][i-seq_len:i], interaction_dicts[user_id]['rating'][i-seq_len:i], interaction_dicts[user_id]['movie_id'][i], interaction_dicts[user_id]['rating'][i], interaction_dicts[user_id]['timestamp'][i].strip('\\n')]\n",
    "        )\n",
    "print(len(sequential_interaction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "sequential_interaction_list = sorted(sequential_interaction_list, key=lambda x: int(x[-1]))\n",
    "with open('./train.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'history_movie_id', 'history_rating', 'movie_id', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[:int(len(sequential_interaction_list)*0.8)])\n",
    "with open('./valid.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'history_movie_id', 'history_rating', 'movie_id', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[int(len(sequential_interaction_list)*0.8):int(len(sequential_interaction_list)*0.9)])\n",
    "with open('./test.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'history_movie_id', 'history_rating', 'movie_id', 'rating', 'timestamp'])\n",
    "    writer.writerows(sequential_interaction_list[int(len(sequential_interaction_list)*0.9):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "# 'user_id', 'history_movie_id', 'history_rating', 'movie_id', 'rating', 'timestamp'\n",
    "def user_specific_description_preprocess(input_path, output_path, sample=False):\n",
    "    data = pd.read_csv(input_path)\n",
    "    with jsonlines.open(output_path, 'w') as writer:\n",
    "        for index, row in data.iterrows():\n",
    "            row['history_movie_id'] = eval(row['history_movie_id'])\n",
    "            row['history_rating'] = eval(row['history_rating'])\n",
    "            L = len(row['history_movie_id'])\n",
    "            preference = []\n",
    "            unpreference = []\n",
    "            for i in range(L):\n",
    "                if int(row['history_rating'][i]) == 1:\n",
    "                    preference.append(movie_dict[row['history_movie_id'][i]])\n",
    "                else:\n",
    "                    unpreference.append(movie_dict[row['history_movie_id'][i]])\n",
    "            target_movie = movie_dict[str(row['movie_id'])]\n",
    "            preference_str = \"\"\n",
    "            unpreference_str = \"\"\n",
    "            for i in range(len(preference)):\n",
    "                if i == 0:\n",
    "                    preference_str += \"\\\"\" + preference[i] + \"\\\"\"\n",
    "                else:\n",
    "                    preference_str += \", \\\"\" + preference[i] + \"\\\"\"\n",
    "            for i in range(len(unpreference)):\n",
    "                if i == 0:\n",
    "                    unpreference_str += \"\\\"\" + unpreference[i] + \"\\\"\"\n",
    "                else:\n",
    "                    unpreference_str += \", \\\"\" + unpreference[i] + \"\\\"\"\n",
    "            target_movie_str = \"\\\"\" + target_movie + \"\\\"\"\n",
    "            # json_list.append({\n",
    "            #     \"instruction\": \"Given ten movies that the user likes and dislikes, please recommend a new movie that the user likes to the user.\",\n",
    "            #     \"input\": f\"User Likes: {preference_str}\\nUser Dislikes: {unpreference_str}\\n \",\n",
    "            #     \"output\": target_movie_str,\n",
    "            # })\n",
    "            temp_inputs = f'''The user enjoy the following movies in the past: {preference_str}. \n",
    "The user doesn't like the following movies in the past: {unpreference_str}.\n",
    "Now please recommend the movie the movie -- {target_movie_str} by writting a description with at most fifty words and at least thirty words. \n",
    "Try to extract similarities from the movies that users like to attract users, while avoiding content that is similar to movies that users don't like.\n",
    "Please begin with \\\"I recommend the movie {target_movie_str} to you.\\\"'''\n",
    "            \n",
    "            writer.write({\"inputs\": temp_inputs})\n",
    "user_specific_description_preprocess('./generative/train_balance.csv', './user_specific_pre.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "# 'user_id', 'history_movie_id', 'history_rating', 'movie_id', 'rating', 'timestamp'\n",
    "f = open('movie_description.txt', 'r')\n",
    "movie_description = f.readlines()\n",
    "f.close()\n",
    "def csv_to_json(input_path, output_path, sample=False, balance=False):\n",
    "    data = pd.read_csv(input_path)\n",
    "    if sample and balance:\n",
    "        return None\n",
    "    if balance:\n",
    "        item_set = set()\n",
    "        data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        index_list = []\n",
    "        for index, row in data.iterrows():\n",
    "            item_id = row['item_title']\n",
    "            if item_id not in item_set:\n",
    "                item_set.add(item_id)\n",
    "                index_list.append(index)\n",
    "        data = data.iloc[index_list]\n",
    "        data.to_csv(output_path[:-5] + \".csv\", index=False)\n",
    "    if sample:\n",
    "        data = data.sample(n=5000, random_state=42).reset_index(drop=True)\n",
    "        data.to_csv(output_path[:-5] + \".csv\", index=False)\n",
    "    json_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        # print(row['user_id'], row['history_movie_id'], row['history_rating'], row[\n",
    "        # 'movie_id'], row['rating'], row['timestamp'])\n",
    "        row['history_movie_id'] = eval(row['history_movie_id'])\n",
    "        row['history_rating'] = eval(row['history_rating'])\n",
    "        L = len(row['history_movie_id'])\n",
    "        history = \"The user has watched the following movies before:\"\n",
    "        for i in range(L):\n",
    "            if i == 0:\n",
    "                history += \"\\\"\" + row['history_movie_title'][i] + \"\\\"\"\n",
    "            else:\n",
    "                history += \", \\\"\" + row['history_movie_title'][i] + \"\\\"\"\n",
    "        target_movie_name = \"\\\"\" + movie_dict[str(row['movie_id'])] + \"\\\"\"\n",
    "        json_list.append({\n",
    "            \"instruction\": \"Given a list of movies the user has watched before, please recommend a new movie that the user likes to the user.\",\n",
    "            \"input\": f\"{history}\\n \",\n",
    "            \"output\": target_movie_name,\n",
    "        })    \n",
    "        \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_json('./train.csv', './train.json')\n",
    "csv_to_json('./valid.csv', './valid.json')\n",
    "csv_to_json('./test.csv', './test.json')\n",
    "csv_to_json('./valid.csv', './valid_balance.json', balance=True)\n",
    "csv_to_json('./test.csv', './test_balance.json', balance=True)\n",
    "csv_to_json('./valid.csv', './valid_5000.json', sample=True)\n",
    "csv_to_json('./test.csv', './test_5000.json', sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59fa845e12d05d721e6f4368480cbf49d04f4a649a02e83c3e47bffdee3cc61a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
